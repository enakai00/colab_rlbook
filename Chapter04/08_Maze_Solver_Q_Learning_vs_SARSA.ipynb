{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Maze_Solver_Q_Learning_vs_SARSA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4a1a7JROZGi",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-01]**\n",
        "\n",
        "Import modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWOOgNK0ygdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rcParams['font.size'] = 12"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlgq5d-FOdcl",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-02]**\n",
        "\n",
        "Define a function to get the maze data in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg8JzPgGwhjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_maze():\n",
        "  maze_img = '''\n",
        "#----------#\n",
        "#S        G#\n",
        "#   ####   #\n",
        "#   ####   #\n",
        "#          #\n",
        "#          #\n",
        "#          #\n",
        "############\n",
        "'''\n",
        "  maze = []\n",
        "  for line in maze_img.split('\\n'):\n",
        "    if line == '':\n",
        "      continue \n",
        "    maze.append(list(line))\n",
        "\n",
        "  return maze"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbKuB8DDOi5K",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-03]**\n",
        "\n",
        "Define the Agent class to walk through the maze."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBHd9TZXzcEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self, maze):\n",
        "    self.maze = maze\n",
        "    size_y, size_x = len(maze), len(maze[0])\n",
        "    self.states = [(x, y) for x in range(size_x) for y in range(size_y)]\n",
        "    self.actions = [(0, -1), (-1, 0), (1, 0), (0, 1)]\n",
        "\n",
        "    self.policy = {}\n",
        "    for s in self.states:\n",
        "      self.policy[s] = self.actions[np.random.randint(len(self.actions))]\n",
        "\n",
        "    self.q = {}\n",
        "    for s in self.states:\n",
        "      for a in self.actions:\n",
        "        self.q[(s, a)] = 0\n",
        "\n",
        "  def move(self, s, a):\n",
        "    x, y = s\n",
        "    dx, dy = a\n",
        "\n",
        "    if self.maze[y][x] == 'G':\n",
        "      return 0, s         # Reward, Next state\n",
        " \n",
        "    if self.maze[y+dy][x+dx] != '#':\n",
        "      x += dx\n",
        "      y += dy\n",
        "\n",
        "    if self.maze[y][x] == '-':\n",
        "      return -100, (1, 1) # Reward, Next state\n",
        "\n",
        "    return -1, (x, y)     # Reward, Next state"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2SvHJSyOmJl",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-04]**\n",
        "\n",
        "Define a function to update the action policy for a specific state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcm3oHfH4dHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def policy_update(agent, s):\n",
        "  q_max = -10**10\n",
        "  a_best = None\n",
        "  for a in agent.actions:\n",
        "    if agent.q[(s, a)] > q_max:\n",
        "      q_max = agent.q[(s, a)]\n",
        "      a_best = a\n",
        "\n",
        "  agent.policy[s] = a_best"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLl5EvK3Q9TG",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-05]**\n",
        "\n",
        "Define a function to apply the Q-Leanring algorithm for a single episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LnnsBQ72xSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_episode_ql(agent, epsilon, train):\n",
        "  episode = []\n",
        "  s = (1, 1)  # Start\n",
        "  while True:\n",
        "    if np.random.random() < epsilon:\n",
        "      a = agent.actions[np.random.randint(len(agent.actions))]\n",
        "    else:\n",
        "      a = agent.policy[s]\n",
        "\n",
        "    r, s_new = agent.move(s, a)\n",
        "    episode.append((s, a, r))\n",
        "\n",
        "    if train:\n",
        "      agent.q[(s, a)] += 0.2 * (r + agent.q[(s_new, agent.policy[s_new])] - agent.q[(s, a)])\n",
        "      policy_update(agent, s)\n",
        "\n",
        "    x, y = s_new\n",
        "    if agent.maze[y][x] == 'G':\n",
        "      break\n",
        "    s = s_new\n",
        "\n",
        "  return episode"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GAZDmswRB-A",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-06]**\n",
        "\n",
        "Define a function to apply the SARSA algorithm for a single episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxcZ_iqlLFNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_episode_salsa(agent, epsilon, train):\n",
        "  episode = []\n",
        "  s = (1, 1)  # Start\n",
        "  if np.random.random() < epsilon:\n",
        "    a = agent.actions[np.random.randint(len(agent.actions))]\n",
        "  else:\n",
        "    a = agent.policy[s]\n",
        "\n",
        "  while True:\n",
        "    r, s_new = agent.move(s, a)\n",
        "    episode.append((s, a, r))\n",
        "\n",
        "    if np.random.random() < epsilon:\n",
        "      a_new = agent.actions[np.random.randint(len(agent.actions))]\n",
        "    else:\n",
        "      a_new = agent.policy[s_new]\n",
        "\n",
        "    if train:\n",
        "      agent.q[(s, a)] += 0.2 * (r + agent.q[(s_new, a_new)] - agent.q[(s, a)])\n",
        "      policy_update(agent, s)\n",
        "\n",
        "    x, y = s_new\n",
        "    if agent.maze[y][x] == 'G':\n",
        "      break\n",
        "    a = a_new\n",
        "    s = s_new\n",
        "\n",
        "  return episode"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySra2s3fRE0e",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-07]**\n",
        "\n",
        "Define a function to train the agent with the Q-Learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KL6VvpZ8ORG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ql(agent, epsilon, num):\n",
        "  episode_lengths = []\n",
        "\n",
        "  for _ in range(num):\n",
        "    episode = get_episode_ql(agent, epsilon, train=True)\n",
        "    episode_lengths.append(len(episode))\n",
        "\n",
        "  return episode_lengths"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPM97MXzRIQf",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-08]**\n",
        "\n",
        "Define a function to train the agent with the SARSA algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trjbPUNgLesb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_salsa(agent, epsilon, num):\n",
        "  episode_lengths = []\n",
        "\n",
        "  for _ in range(num):\n",
        "    episode = get_episode_salsa(agent, epsilon, train=True)\n",
        "    episode_lengths.append(len(episode))\n",
        "\n",
        "  return episode_lengths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REKyfljzRKv_",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-09]**\n",
        "\n",
        "Apply the Q-Learning algorithm to train the agent, and show the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjBNsr8-MwOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b717aede-1c9a-426d-c884-c71cfedb57a6"
      },
      "source": [
        "maze = get_maze()\n",
        "agent = Agent(maze)\n",
        "episode_lengths = train_ql(agent, epsilon=0.1, num=1000)\n",
        "\n",
        "episode = get_episode_ql(agent, epsilon=0, train=False)\n",
        "result = np.copy(agent.maze)\n",
        "for (s, a, r) in episode:\n",
        "  x, y = s\n",
        "  result[y][x] = '+'\n",
        "for line in result:\n",
        "  print (''.join(line))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#----------#\n",
            "#+++++++++G#\n",
            "#   ####   #\n",
            "#   ####   #\n",
            "#          #\n",
            "#          #\n",
            "#          #\n",
            "############\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaLWsotERgQ9",
        "colab_type": "text"
      },
      "source": [
        "**[MQS-10]**\n",
        "\n",
        "Apply the SARSA algorithm to train the agent, and show the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZiJ5Ao9cAmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "19108376-24e9-40b6-8bc3-8b462ba5531e"
      },
      "source": [
        "maze = get_maze()\n",
        "agent = Agent(maze)\n",
        "episode_lengths = train_salsa(agent, epsilon=0.1, num=1000)\n",
        "\n",
        "episode = get_episode_salsa(agent, epsilon=0, train=False)\n",
        "result = np.copy(agent.maze)\n",
        "for (s, a, r) in episode:\n",
        "  x, y = s\n",
        "  result[y][x] = '+'\n",
        "for line in result:\n",
        "  print (''.join(line))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#----------#\n",
            "#+        G#\n",
            "#+  ####  +#\n",
            "#+  ####+++#\n",
            "#++++++++  #\n",
            "#          #\n",
            "#          #\n",
            "############\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}