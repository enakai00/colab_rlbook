{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp_QdSaLXEea"
      },
      "source": [
        "**[WGT-01]**\n",
        "\n",
        "Specify the TensorFlow version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzsWr-VHKQ_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059a06aa-c856-4731-be0f-0e327c10f325"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo087BQEXLEo"
      },
      "source": [
        "**[WGT-02]**\n",
        "\n",
        "Import modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxl0MUcjZS37"
      },
      "source": [
        "import numpy as np\n",
        "import copy, random, time\n",
        "from tensorflow.keras import layers, models\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqNp9SXMXNvM"
      },
      "source": [
        "**[WGT-03]**\n",
        "\n",
        "Define a function to get the field data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnfMnWb941ES"
      },
      "source": [
        "def get_field():\n",
        "  field_img = '''\n",
        "##############\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "#            #\n",
        "##############\n",
        "'''\n",
        "  field = []\n",
        "  for line in field_img.split('\\n'):\n",
        "    if line == '':\n",
        "      continue \n",
        "    field.append(list(line))\n",
        "\n",
        "  return field"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0RQFTAMXamz"
      },
      "source": [
        "**[WGT-04]**\n",
        "\n",
        "Define the Environ class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsMHAlFTgGCs"
      },
      "source": [
        "class Environ:\n",
        "  def __init__(self):\n",
        "    self.action_map = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
        "    self.restart()\n",
        "\n",
        "  def restart(self):\n",
        "    self.field = get_field()\n",
        "    for _ in range(10):\n",
        "      y = np.random.randint(1, 13)\n",
        "      x = np.random.randint(1, 13)\n",
        "      self.field[y][x] = 'x'\n",
        "\n",
        "  def move(self, s, a):\n",
        "    x, y = s\n",
        "    dx, dy = self.action_map[a]\n",
        "    self.field[y][x] = '+'\n",
        "    x += dx\n",
        "    y += dy\n",
        "    s_new = (x, y)\n",
        "    if self.field[y][x] != ' ':\n",
        "      return 0, s_new, True   # Reward, Next position, Is game over?\n",
        "    return 1, s_new, False    # Reward, Next position, Is game over?\n",
        "\n",
        "  def get_state(self, s):\n",
        "    x, y = s\n",
        "    walls = [[0.0 if c == ' ' else 1.0 for c in line] for line in self.field]\n",
        "    walker = np.zeros((14, 14))\n",
        "    walker[y][x] = 1.0\n",
        "    state = np.zeros((14, 14, 2))\n",
        "    state[:, :, 0] = walls\n",
        "    state[:, :, 1] = walker\n",
        "    return state.tolist()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Jj55WLXgIT"
      },
      "source": [
        "**[WGT-05]**\n",
        "\n",
        "Define the QValue class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TWxe5DjPAQU"
      },
      "source": [
        "class QValue:\n",
        "  def __init__(self):\n",
        "    self.model = self.build_model()\n",
        "\n",
        "  def build_model(self):\n",
        "    cnn_input = layers.Input(shape=(14, 14, 2))\n",
        "    cnn = layers.Conv2D(8, (5, 5), padding='same', use_bias=True,\n",
        "                        activation='relu')(cnn_input)\n",
        "    cnn_flatten = layers.Flatten()(cnn)\n",
        "\n",
        "    action_input = layers.Input(shape=(4,))\n",
        "\n",
        "    combined = layers.concatenate([cnn_flatten, action_input])\n",
        "    hidden1 = layers.Dense(2048, activation='relu')(combined)\n",
        "    hidden2 = layers.Dense(1024, activation='relu')(hidden1)\n",
        "    q_value = layers.Dense(1)(hidden2)\n",
        "\n",
        "    model = models.Model(inputs=[cnn_input, action_input], outputs=q_value)\n",
        "    model.compile(loss='mse')\n",
        "    return model\n",
        "\n",
        "  def get_action(self, state):\n",
        "    states = []\n",
        "    actions = []\n",
        "    for a in range(4):\n",
        "      states.append(np.array(state))\n",
        "      action_onehot = np.zeros(4)\n",
        "      action_onehot[a] = 1\n",
        "      actions.append(action_onehot)\n",
        "  \n",
        "    q_values = self.model.predict([np.array(states), np.array(actions)], verbose=0)\n",
        "    optimal_action = np.argmax(q_values)\n",
        "    return optimal_action, q_values[optimal_action][0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IhaMsexXkk8"
      },
      "source": [
        "**[WGT-06]**\n",
        "\n",
        "Define a function to get a single episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLvGh76GPZ-c"
      },
      "source": [
        "def get_episode(environ, q_value, epsilon):\n",
        "  episode = []\n",
        "  trace = []\n",
        "  environ.restart()\n",
        "  s = (np.random.randint(1, 13), np.random.randint(1, 13))\n",
        "\n",
        "  while True:\n",
        "    trace.append(s)\n",
        "    state = environ.get_state(s)\n",
        "    if np.random.random() < epsilon:\n",
        "      a = np.random.randint(4)\n",
        "    else:\n",
        "      a, _ = q_value.get_action(state)\n",
        "\n",
        "    r, s_new, game_over = environ.move(s, a)\n",
        "    if game_over:\n",
        "      state_new = None\n",
        "    else:\n",
        "      state_new = environ.get_state(s_new)\n",
        "    episode.append((state, a, r, state_new))\n",
        "\n",
        "    if game_over:\n",
        "      break\n",
        "    s = s_new\n",
        "\n",
        "  return episode, trace"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RISCHxLPXpIJ"
      },
      "source": [
        "**[WGT-07]**\n",
        "\n",
        "Define a function to show a sample episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltSHgYpCg_Jc"
      },
      "source": [
        "  def show_sample(environ, q_value):\n",
        "    _, trace = get_episode(environ, q_value, epsilon=0)\n",
        "    display = copy.deepcopy(environ.field)\n",
        "    display = [[' ' if c == '+' else c for c in line] for line in display]\n",
        "    for s in trace:\n",
        "      x, y = s\n",
        "      display[y][x] = '*'\n",
        "      time.sleep(0.5)\n",
        "      clear_output(wait=True)\n",
        "      for line in display:\n",
        "        print(''.join(line))\n",
        "      display[y][x] = '+'\n",
        "\n",
        "    print('Length: {}'.format(len(trace)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvKPo6tvX0xo"
      },
      "source": [
        "**[WGT-08]**\n",
        "\n",
        "Define a function to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p23cs6rYQoou"
      },
      "source": [
        "def train(environ, q_value, num):\n",
        "  experience = []\n",
        "  for c in range(num):\n",
        "    print()\n",
        "    print('Iteration {}'.format(c+1))\n",
        "    print('Collecting data', end='')\n",
        "    for n in range(50):\n",
        "      print('.', end='')\n",
        "      if n % 10 == 0:\n",
        "        epsilon = 0\n",
        "      else:\n",
        "        epsilon = 0.2\n",
        "      episode, _ = get_episode(environ, q_value, epsilon)\n",
        "      experience += episode\n",
        "    if len(experience) > 10000:\n",
        "      experience = experience[-10000:]\n",
        "\n",
        "    if len(experience) < 1000:\n",
        "      continue\n",
        "\n",
        "    print()\n",
        "    print('Training the model...')\n",
        "    examples = experience[-200:] + random.sample(experience[:-200], 400)\n",
        "    np.random.shuffle(examples)\n",
        "    states, actions, labels = [], [], []\n",
        "    for state, a, r, state_new in examples:\n",
        "      states.append(np.array(state))\n",
        "      action_onehot = np.zeros(len(environ.action_map))\n",
        "      action_onehot[a] = 1\n",
        "      actions.append(action_onehot)\n",
        "      if not state_new:   # Terminal state\n",
        "        q_new = 0\n",
        "      else:\n",
        "        _, q_new = q_value.get_action(state_new)\n",
        "      labels.append(np.array(r + q_new))\n",
        "    q_value.model.fit([np.array(states), np.array(actions)], np.array(labels),\n",
        "                      batch_size=50, epochs=100, verbose=0)\n",
        "    show_sample(environ, q_value)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGN33L5iX4od"
      },
      "source": [
        "**[WGT-09]**\n",
        "\n",
        "Create as Environ instance and a QValue instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koY7dyBFrzPr",
        "outputId": "3e16758e-3291-420e-8128-c53a6a82948b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "environ = Environ()\n",
        "q_value = QValue()\n",
        "q_value.model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 14, 14, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 14, 14, 8)    408         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1568)         0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1572)         0           ['flatten[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2048)         3221504     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1024)         2098176     ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            1025        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,321,113\n",
            "Trainable params: 5,321,113\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LCIQv9pYEUI"
      },
      "source": [
        "**[WGT-10]**\n",
        "\n",
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evsdScWmr6N4",
        "outputId": "f575de4e-242c-4c5b-8b05-f093269cfd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train(environ, q_value, num=40)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############\n",
            "#            #\n",
            "#            #\n",
            "#      x     #\n",
            "#            #\n",
            "#x   x  x    #\n",
            "#        x   #\n",
            "# x   x    x #\n",
            "# +++        #\n",
            "# +x+        #\n",
            "# ++*        #\n",
            "#  + ++  x   #\n",
            "#  +++       #\n",
            "##############\n",
            "Length: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XASq_TKCYIm_"
      },
      "source": [
        "**[WGT-11]**\n",
        "\n",
        "Show a sample episode using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsZBDhGUTxI6",
        "outputId": "f4ae04ed-8ae6-43f4-defa-f2f4e6576416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "show_sample(environ, q_value)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############\n",
            "#            #\n",
            "#x       x   #\n",
            "#            #\n",
            "#  +         #\n",
            "#  ++x       #\n",
            "#   +        #\n",
            "#  ++        #\n",
            "#x ++  x     #\n",
            "#   +        #\n",
            "# +++       x#\n",
            "# *x         #\n",
            "#  x    x x  #\n",
            "##############\n",
            "Length: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1nmU_LkYPLU"
      },
      "source": [
        "**[WGT-12]**\n",
        "\n",
        "Mount the Google drive on the runtime environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgX4hxUoLzgi",
        "outputId": "970b9400-af47-4a7c-93ef-7c950b7de66a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snfavh-qYZl2"
      },
      "source": [
        "**[WGT-13]**\n",
        "\n",
        "Save the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmqyrkzOClgB",
        "outputId": "4707267d-9044-485e-9fc8-d835717a5c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q_value.model.save('/content/gdrive/My Drive/walk_game_model.hd5', save_format='h5')\n",
        "!ls -l '/content/gdrive/My Drive/walk_game_model.hd5'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 42607352 May  8 04:32 '/content/gdrive/My Drive/walk_game_model.hd5'\n"
          ]
        }
      ]
    }
  ]
}